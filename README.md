# ğŸ•µï¸ Automatizador de Reclutamiento (Job Scraper)

Herramienta construida con **Clean Architecture** para la extracciÃ³n automatizada de candidatos de portales de empleo como OCC Mundial y Pandape.

## ğŸš€ Stack TecnolÃ³gico

*   **Lenguaje**: Python 3.12+
*   **Gestor de Paquetes**: `uv`
*   **ValidaciÃ³n de Datos**: Pydantic
*   **Motor de Scraping**: Playwright
*   **Interfaz de Usuario**: Streamlit
*   **Arquitectura**: Clean Architecture (Domain, Application, Infrastructure, UI)

### ğŸ“‚ Arquitectura del Proyecto (Clean Architecture)
El proyecto sigue una arquitectura en capas para garantizar la escalabilidad y mantenibilidad:

```text
src/
â”œâ”€â”€ domain/                  # Capa de Dominio (Reglas de Negocio)
â”‚   â”œâ”€â”€ models.py            # Entidades de datos (CandidateSchema, JobPost)
â”‚   â””â”€â”€ interfaces.py        # Contratos / Interfaces (BaseScraper, DataExporter)
â”‚
â”œâ”€â”€ application/             # Capa de AplicaciÃ³n (Casos de Uso)
â”‚   â””â”€â”€ services.py          # Servicios orquestadores (CandidateSearchService)
â”‚
â”œâ”€â”€ infraestructura/         # Capa de Infraestructura (Implementaciones)
â”‚   â”œâ”€â”€ scrapers/            # Adaptadores de Scraping
â”‚   â”‚   â”œâ”€â”€ occ_scraper.py   # ImplementaciÃ³n para OCC
â”‚   â”‚   â”œâ”€â”€ pandape_scraper.py # Base para Pandape
â”‚   â”‚   â””â”€â”€ pandape_base_propia_scraper.py # Scraper especializado (Harvest/Process)
â”‚   â”œâ”€â”€ persistence/         # Adaptadores de Persistencia
â”‚   â”‚   â”œâ”€â”€ json_exporter.py # ExportaciÃ³n a JSONL
â”‚   â”‚   â”œâ”€â”€ csv_exporter.py  # ExportaciÃ³n a CSV (Hybrid Flattening)
â”‚   â”‚   â”œâ”€â”€ toml_exporter.py # ExportaciÃ³n a TOML
â”‚   â”‚   â””â”€â”€ toon_exporter.py # ExportaciÃ³n a TOON
â”‚   â””â”€â”€ logging.py           # ConfiguraciÃ³n centralizada de logs
â”‚
â”œâ”€â”€ ui/                      # Capa de Interfaz
â”‚   â””â”€â”€ app.py               # AplicaciÃ³n Web con Streamlit
â”‚
â”œâ”€â”€ main.py                  # Entry point (CLI BÃ¡sico)
â”œâ”€â”€ main_base_propia.py      # Entry point (ExtracciÃ³n Masiva)
â”œâ”€â”€ main_exporters.py        # Entry point (ConversiÃ³n de Formatos)
â”œâ”€â”€ .env                     # Variables de entorno (Credenciales)
â””â”€â”€ pyproject.toml           # DefiniciÃ³n de dependencias
```

### DescripciÃ³n de Componentes

*   **Domain**: Define *quÃ©* hace el sistema. Contiene los modelos de datos (`models.py`) que representan a los candidatos y las interfaces (`interfaces.py`) que dictan cÃ³mo deben comportarse los scrapers y exportadores, sin preocuparse de la implementaciÃ³n.
*   **Application**: Define *cÃ³mo* se coordinan las tareas. `services.py` contiene la lÃ³gica principal (e.g., `CandidateSearchService`) que utiliza las interfaces del dominio para ejecutar la bÃºsqueda, extracciÃ³n y guardado de datos.
*   **Infrastructure**: Contiene los detalles tÃ©cnicos. AquÃ­ viven los scrapers reales (`occ_scraper.py`, `pandape_scraper.py`) que interactÃºan con los sitios web usando Playwright, y los exportadores (`json_exporter.py`, `csv_exporter.py`, etc.) que escriben en disco en varios formatos.
*   **UI**: La interfaz de usuario. `app.py` utiliza los servicios de la capa de aplicaciÃ³n para mostrar resultados al usuario final.

## ğŸ› ï¸ InstalaciÃ³n

Este proyecto utiliza `uv` para la gestiÃ³n de dependencias.

1.  **Clonar el repositorio**:
    ```bash
    git clone <url-del-repo>
    cd Automatizador_reclutamiento
    ```

2.  **Instalar dependencias**:
    ```bash
    uv sync
    ```

3.  **Instalar navegadores de Playwright**:
    ```bash
    uv run playwright install chromium
    ```

3.  **ConfiguraciÃ³n de Variables de Entorno**:
    Copia el archivo de ejemplo y configura tus credenciales:
    ```bash
    cp .env.example .env
    ```
    Edita `.env` con tus usuarios y contraseÃ±as de OCC/Pandape.

## â–¶ï¸ EjecuciÃ³n

Puedes ejecutar la herramienta de dos formas:

### 1. Interfaz GrÃ¡fica (Recomendado)
Inicia la aplicaciÃ³n web con Streamlit:
```bash
uv run streamlit run src/ui/app.py
```

### 2. LÃ­nea de Comandos (CLI)
Ejecuta el script principal para una bÃºsqueda rÃ¡pida en terminal:
```bash
uv run python main.py
```

### 3. ExtracciÃ³n Masiva (Base Propia Pandape)
Script especializado para extraer grandes volÃºmenes (60k+) en dos fases:
1.  **Cosecha (Harvest)**: Recolecta IDs rÃ¡pidamente por estado.
2.  **Procesamiento (Worker)**: Enriquece los perfiles uno a uno.

```bash
uv run main_base_propia.py
```

### 4. Herramientas de ExportaciÃ³n
Convierte tus archivos JSONL recolectados a otros formatos (CSV, TOML, TOON):

```bash
# Sintaxis: uv run main_exporters.py <input_file> <format>
uv run main_exporters.py data/candidatos_completos.jsonl csv
uv run main_exporters.py data/candidatos_completos.jsonl toon
```
**Formatos soportados:** `csv`, `toml`, `toon`.

## ğŸ“ Notas
*   Los resultados se guardan automÃ¡ticamente en la carpeta `data/` en formato JSON.
*   AsegÃºrate de no abusar de las peticiones para evitar bloqueos por parte de los portales.
